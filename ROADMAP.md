# üìã Roadmap: ML Crawler com Monitoramento de Pre√ßos

## Objetivo
Transformar o scraper em um **monitorador de pre√ßos com hist√≥rico**, coletando dados de m√∫ltiplas categorias automaticamente via Prefect.

---

## üìÇ Estrutura Final do Projeto

```
ml-crawler/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py                 # CLI principal
‚îÇ   ‚îú‚îÄ‚îÄ scraper.py              # Scraping (refatorado)
‚îÇ   ‚îú‚îÄ‚îÄ utils.py                # Utilit√°rios
‚îÇ   ‚îú‚îÄ‚îÄ models.py               # ‚ú® NOVO: Modelos Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ database.py             # ‚ú® NOVO: Gerenciamento BD
‚îÇ   ‚îú‚îÄ‚îÄ config.py               # ‚ú® NOVO: Categorias e URLs
‚îÇ   ‚îú‚îÄ‚îÄ tasks.py                # ‚ú® NOVO: Tasks Prefect
‚îÇ   ‚îî‚îÄ‚îÄ analysis.py             # ‚ú® NOVO: An√°lise de dados
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ ml_crawler.db           # ‚ú® NOVO: Banco SQLite
‚îú‚îÄ‚îÄ logs/                       # ‚ú® NOVO: Logs de execu√ß√£o
‚îú‚îÄ‚îÄ reports/                    # ‚ú® NOVO: Relat√≥rios gerados
‚îú‚îÄ‚îÄ produtos.json               # (Manter compatibilidade)
‚îú‚îÄ‚îÄ requirements.txt            # (Atualizar depend√™ncias)
‚îî‚îÄ‚îÄ README.md
```

---

## üéØ Passo a Passo de Implementa√ß√£o

### PASSO 1Ô∏è‚É£: Definir Categorias de Produtos
**Arquivo:** `src/config.py`

```python
CATEGORIAS = {
    "celulares": {
        "url": "https://lista.mercadolivre.com.br/celular",
        "max_paginas": 5,
        "descricao": "Smartphones e celulares"
    },
    "pcs": {
        "url": "https://lista.mercadolivre.com.br/computador-desktop",
        "max_paginas": 5,
        "descricao": "Computadores desktop"
    },
    "notebooks": {
        "url": "https://lista.mercadolivre.com.br/notebook",
        "max_paginas": 5,
        "descricao": "Notebooks e laptops"
    },
    "eletronicos": {
        "url": "https://lista.mercadolivre.com.br/eletronico",
        "max_paginas": 3,
        "descricao": "Eletr√¥nicos em geral"
    },
    "casa_lar": {
        "url": "https://lista.mercadolivre.com.br/movel",
        "max_paginas": 3,
        "descricao": "M√≥veis e artigos de casa"
    }
}

DATABASE_PATH = "data/ml_crawler.db"
LOG_DIR = "logs"
REPORT_DIR = "reports"
```

### PASSO 2Ô∏è‚É£: Criar Modelo de Dados (Pydantic)
**Arquivo:** `src/models.py`

```python
from pydantic import BaseModel, Field
from datetime import datetime
from typing import Optional

class Produto(BaseModel):
    nome: str
    preco: float
    link: str
    categoria: str
    timestamp: datetime = Field(default_factory=datetime.now)
    
    class Config:
        json_schema_extra = {
            "example": {
                "nome": "Samsung Galaxy A12",
                "preco": 599.99,
                "link": "https://...",
                "categoria": "celulares",
                "timestamp": "2024-11-20T10:30:00"
            }
        }

class ProdutoHistorico(BaseModel):
    produto_id: int
    preco: float
    data: datetime = Field(default_factory=datetime.now)
```

### PASSO 3Ô∏è‚É£: Configurar Banco de Dados
**Arquivo:** `src/database.py`

**Schema:**
```sql
-- Tabela de Produtos
CREATE TABLE IF NOT EXISTS produtos (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    nome TEXT NOT NULL UNIQUE,
    link TEXT NOT NULL UNIQUE,
    categoria TEXT NOT NULL,
    preco_atual REAL,
    primeira_coleta TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    ultima_atualizacao TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Tabela de Hist√≥rico de Pre√ßos
CREATE TABLE IF NOT EXISTS precos_historico (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    produto_id INTEGER NOT NULL,
    preco REAL NOT NULL,
    data TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (produto_id) REFERENCES produtos(id)
);

-- Tabela de Coletas
CREATE TABLE IF NOT EXISTS coletas (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    categoria TEXT NOT NULL,
    data_inicio TIMESTAMP,
    data_fim TIMESTAMP,
    total_produtos INTEGER,
    status TEXT -- 'sucesso', 'erro'
);
```

### PASSO 4Ô∏è‚É£: Integrar Scraper com BD
**Modifica√ß√£o:** `src/scraper.py`

Ao inv√©s de retornar apenas a lista, salvar direto no BD:

```python
def salvar_produto_bd(db, produto: Produto):
    """Salva produto no BD e cria hist√≥rico de pre√ßo"""
    try:
        # Verifica se j√° existe
        produto_existente = db.query(Produto).filter_by(
            nome=produto.nome, 
            link=produto.link
        ).first()
        
        if produto_existente:
            # Atualiza pre√ßo
            produto_existente.preco_atual = produto.preco
            produto_existente.ultima_atualizacao = datetime.now()
            db.add(PrecosHistorico(
                produto_id=produto_existente.id,
                preco=produto.preco
            ))
        else:
            # Cria novo
            db.add(produto)
            db.flush()
            db.add(PrecosHistorico(
                produto_id=produto.id,
                preco=produto.preco
            ))
        
        db.commit()
    except Exception as e:
        db.rollback()
        print(f"‚ùå Erro ao salvar: {e}")
```

### PASSO 5Ô∏è‚É£: Configurar Prefect para Agendamento
**Arquivo:** `src/tasks.py`

```python
from prefect import flow, task
from datetime import datetime, timedelta
import schedule

@task
def scrape_categoria(categoria: str):
    """Task Prefect para scraping de uma categoria"""
    print(f"üöÄ Iniciando scraping: {categoria}")
    # Executar scraper e salvar BD
    
@flow
def coleta_diaria():
    """Flow que coleta todas as categorias"""
    categorias = list(CATEGORIAS.keys())
    for cat in categorias:
        scrape_categoria(cat)
    print("‚úÖ Coleta di√°ria conclu√≠da")

# Agendar para rodar a cada 6 horas
if __name__ == "__main__":
    coleta_diaria.serve(
        cron="0 0,6,12,18 * * *"  # A cada 6 horas
    )
```

### PASSO 6Ô∏è‚É£: An√°lise de Hist√≥rico
**Arquivo:** `src/analysis.py`

```python
def gerar_relatorio_variacao(produto_id: int):
    """Analisa varia√ß√£o de pre√ßo de um produto"""
    historico = db.query(PrecosHistorico).filter_by(
        produto_id=produto_id
    ).all()
    
    precos = [h.preco for h in historico]
    
    return {
        "preco_minimo": min(precos),
        "preco_maximo": max(precos),
        "preco_medio": sum(precos) / len(precos),
        "variacao_percentual": ((precos[-1] - precos[0]) / precos[0]) * 100
    }
```

---

## üì¶ Depend√™ncias Novas

```
prefect==3.0.0           # Agendamento e orquestra√ß√£o
pydantic==2.5.0          # Valida√ß√£o de dados
sqlalchemy==2.0.0        # ORM para BD
sqlite3                  # J√° vem com Python
python-dotenv==1.1.0     # Vari√°veis de ambiente
```

---

## üöÄ Ordem de Implementa√ß√£o

1. **Instalar depend√™ncias** ‚Üí `pip install -r requirements.txt`
2. **Criar `config.py`** ‚Üí Definir categorias
3. **Criar `models.py`** ‚Üí Modelos Pydantic
4. **Criar `database.py`** ‚Üí Schema e fun√ß√µes BD
5. **Refatorar `scraper.py`** ‚Üí Integrar com BD
6. **Criar `tasks.py`** ‚Üí Prefect tasks e flows
7. **Criar `analysis.py`** ‚Üí Scripts de an√°lise
8. **Testar manualmente** ‚Üí Rodar uma coleta
9. **Ativar schedule** ‚Üí Deixar rodando

---

## ‚úÖ Checklist de Implementa√ß√£o

- [ ] Passo 1: Categorias configuradas
- [ ] Passo 2: Modelos Pydantic criados
- [ ] Passo 3: Banco de dados configurado
- [ ] Passo 4: Scraper integrado com BD
- [ ] Passo 5: Prefect tasks criadas
- [ ] Passo 6: Scripts de an√°lise prontos
- [ ] Banco com hist√≥rico de 1 semana
- [ ] Dashboard b√°sico funcionando
- [ ] README atualizado

---

## üìä Resultado Esperado

Ap√≥s implementar tudo:

```
‚úÖ Coletas autom√°ticas a cada 6 horas
‚úÖ Banco de dados com hist√≥rico de pre√ßos
‚úÖ 5+ categorias monitoradas
‚úÖ Relat√≥rios de varia√ß√£o de pre√ßo
‚úÖ Base de dados para compara√ß√£o
‚úÖ Pronto para fase 2: Comparador de Pre√ßos
```

---

**Pr√≥ximo Passo:** Come√ßar pelo Passo 1 (Categorias)
