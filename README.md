# ML Crawler üï∑Ô∏è

Um web scraper poderoso e eficiente para extrair dados de produtos do Mercado Livre Brasil com suporte a **pagina√ß√£o autom√°tica**.

## üìã Descri√ß√£o

ML Crawler √© uma ferramenta desenvolvida em Python que permite coletar informa√ß√µes de produtos (nome, pre√ßo e link) diretamente do Mercado Livre. Ideal para an√°lise de pre√ßos, pesquisa de mercado, compara√ß√£o de produtos e estudo de web scraping.

**Funcionalidades principais:**
- ‚úÖ Extra√ß√£o autom√°tica de dados de produtos
- ‚úÖ Suporte a pagina√ß√£o (m√∫ltiplas p√°ginas)
- ‚úÖ Detec√ß√£o din√¢mica de seletores CSS
- ‚úÖ Exporta√ß√£o em JSON
- ‚úÖ Tratamento robusto de erros
- ‚úÖ Logs informativos em tempo real

## üöÄ Quick Start

### Pr√©-requisitos

- Python 3.7+
- pip (gerenciador de pacotes Python)

### Instala√ß√£o

1. Clone o reposit√≥rio:
```bash
git clone <seu-reposit√≥rio>
cd ml-crawler
```

2. Instale as depend√™ncias:
```bash
pip install -r requirements.txt
```

### Uso B√°sico

Execute o script com uma URL do Mercado Livre:

```bash
# Scraping da URL padr√£o
python -m src.main

# Scraping com URL espec√≠fica
python -m src.main "https://lista.mercadolivre.com.br/celular"

# Com limite de produtos (ex: 100 produtos)
python -m src.main "https://lista.mercadolivre.com.br/celular" 100

# Com limite de produtos E p√°ginas (ex: 100 produtos, m√°ximo 5 p√°ginas)
python -m src.main "https://lista.mercadolivre.com.br/celular" 100 5
```

## üì¶ Estrutura do Projeto

```
ml-crawler/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.py          # Ponto de entrada da aplica√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ scraper.py       # L√≥gica de scraping e pagina√ß√£o
‚îÇ   ‚îî‚îÄ‚îÄ utils.py         # Fun√ß√µes utilit√°rias
‚îú‚îÄ‚îÄ produtos.json        # Arquivo de sa√≠da com produtos extra√≠dos
‚îú‚îÄ‚îÄ requirements.txt     # Depend√™ncias do projeto
‚îî‚îÄ‚îÄ README.md           # Este arquivo
```

## üîß Componentes

### `main.py`
Orquestra a execu√ß√£o do scraper. Recebe par√¢metros via linha de comando:
- `URL`: URL do Mercado Livre (opcional)
- `max_produtos`: N√∫mero m√°ximo de produtos (opcional)
- `max_paginas`: N√∫mero m√°ximo de p√°ginas (opcional, padr√£o: 10)

### `scraper.py`
Cont√©m as principais fun√ß√µes de scraping:

- **`fetch_html(url: str) -> str`**
  - Faz requisi√ß√£o HTTP √† URL
  - Retorna o HTML da p√°gina
  - Exibe status HTTP

- **`detect_selector(html: str) -> str`**
  - Detecta automaticamente qual seletor CSS usar
  - Suporta m√∫ltiplos layouts do Mercado Livre
  - Retorna None se nenhum seletor for encontrado

- **`extract_products(html: str, limit: int) -> list`**
  - Extrai produtos do HTML
  - Limita quantidade de produtos por p√°gina
  - Retorna lista com nome, pre√ßo e link

- **`add_pagination_to_url(url: str, page: int) -> str`**
  - Adiciona/atualiza par√¢metro `_Paging` na URL
  - Preserva outros par√¢metros existentes
  - Retorna URL paginada

- **`scrape_all_pages(base_url: str, max_products: int, max_pages: int) -> list`**
  - Itera sobre m√∫ltiplas p√°ginas
  - Para automaticamente quando n√£o h√° mais produtos
  - Respeita limites de produtos e p√°ginas

### `utils.py`
Utilit√°rios para processamento de dados:

- **`text_to_price(s: str) -> float`**
  - Converte texto em pre√ßo num√©rico
  - Remove caracteres especiais
  - Trata v√≠rgulas e pontos corretamente

## üìä Formato de Sa√≠da

O arquivo `produtos.json` gerado cont√©m:

```json
[
  {
    "nome": "Samsung Galaxy A12 128GB",
    "preco": 599.99,
    "link": "https://produto.mercadolivre.com.br/..."
  },
  {
    "nome": "iPhone 12 64GB",
    "preco": 3299.00,
    "link": "https://produto.mercadolivre.com.br/..."
  }
]
```

## üéØ Exemplos de Uso

### Exemplo 1: Buscar Todos os Celulares (sem limites)
```bash
python -m src.main "https://lista.mercadolivre.com.br/celular"
```

### Exemplo 2: Primeiros 50 produtos de Notebooks
```bash
python -m src.main "https://lista.mercadolivre.com.br/notebook" 50
```

### Exemplo 3: An√°lise de Laptops (3 p√°ginas, m√°ximo 150 produtos)
```bash
python -m src.main "https://lista.mercadolivre.com.br/laptop" 150 3
```

### Exemplo 4: Busca com filtros do Mercado Livre
```bash
python -m src.main "https://lista.mercadolivre.com.br/smartphone/_PriceRange_100000-500000" 100 5
```

## üõ†Ô∏è Requisitos

Veja `requirements.txt`:

```
requests==2.31.0      # Requisi√ß√µes HTTP
beautifulsoup4==4.12.2 # Parsing HTML
lxml==4.9.3           # Parser XML/HTML r√°pido
```

## ‚ö†Ô∏è Notas Importantes

- **Respeite o `robots.txt`**: Mercado Livre pode ter limita√ß√µes para scraping autom√°tico
- **Delays entre requisi√ß√µes**: Considere adicionar delays para n√£o sobrecarregar os servidores
- **Mudan√ßas na estrutura HTML**: O site pode mudar, afetando os seletores CSS
- **Termos de Servi√ßo**: Verifique a viabilidade legal do seu projeto

## üö® Troubleshooting

### Problema: "‚ùå Nenhum seletor compat√≠vel encontrado"
**Solu√ß√£o:** O HTML do Mercado Livre pode ter mudado. Atualize os seletores em `detect_selector()`

### Problema: "Timeout Error"
**Solu√ß√£o:** Aumente o timeout em `fetch_html()` ou verifique sua conex√£o

### Problema: Pre√ßos n√£o est√£o sendo extra√≠dos
**Solu√ß√£o:** Verifique se a fun√ß√£o `text_to_price()` est√° processando corretamente o formato

## üìà Melhorias Futuras

### Fase 1: Monitoramento de Pre√ßos
- [ ] **Agendamento autom√°tico (APScheduler)**
  - Executar scraping em intervalos regulares (ex: a cada 6 horas)
  - Hist√≥rico de coletas autom√°tico
  - Logs de execu√ß√£o

- [ ] **Banco de dados (SQLite/PostgreSQL)**
  - Armazenar hist√≥rico de pre√ßos
  - Rastrear mudan√ßas de pre√ßo por produto
  - Schema: `produtos`, `precos_historico`, `buscas`

- [ ] **Monitoramento de mudan√ßas de pre√ßo**
  - Alertas quando pre√ßo cai/sobe
  - Compara√ß√£o com pre√ßo anterior
  - Relat√≥rios de varia√ß√£o percentual

### Fase 2: An√°lise e Visualiza√ß√£o
- [ ] **Interface gr√°fica (Streamlit)**
  - Dashboard com gr√°ficos de pre√ßos
  - Filtros por categoria/produto
  - Visualiza√ß√£o de tend√™ncias

- [ ] **Exporta√ß√£o de dados**
  - CSV e Excel com hist√≥rico completo
  - Gr√°ficos em PDF
  - Relat√≥rios autom√°ticos por email

### Fase 3: Dados e Valida√ß√£o
- [ ] **Valida√ß√£o de dados (Pydantic)**
  - Schema de produto validado
  - Tratamento de tipos de dados
  - Mensagens de erro claras

- [ ] **An√°lise de pre√ßos**
  - Pre√ßo m√≠nimo/m√°ximo/m√©dio
  - Detec√ß√£o de outliers
  - Recomenda√ß√µes de compra


### Roadmap de Implementa√ß√£o

**v1.1** (Pr√≥xima):
```
- Banco de dados SQLite
- Hist√≥rico de pre√ßos
- Valida√ß√£o com Pydantic
```

**v1.2**:
```
- APScheduler para execu√ß√£o autom√°tica
- Alertas de mudan√ßa de pre√ßo
- Logs estruturados
```

**v1.3**:
```
- Dashboard Streamlit b√°sico
- Gr√°ficos de tend√™ncias
- Exporta√ß√£o CSV
```

**v2.0**:
```
- PostgreSQL para escala
- API REST (FastAPI)
- Notifica√ß√µes por email/Telegram
- Dashboard avan√ßado
```

## üìù Licen√ßa

Este projeto √© fornecido como est√° para fins educacionais e de portf√≥lio.

## üí° Aprendizados

Este projeto demonstra conhecimento em:
- **Web Scraping**: T√©cnicas de extra√ß√£o de dados da web
- **Parsing HTML**: Uso de BeautifulSoup e XPath
- **Programa√ß√£o Python**: Modulariza√ß√£o, tratamento de erros
- **APIs HTTP**: Requisi√ß√µes e headers
- **Processamento de Dados**: Limpeza e formata√ß√£o
- **Estrutura de Projetos**: Organiza√ß√£o e boas pr√°ticas

## üë§ Autor

Wyvig Israel

## ü§ù Contribui√ß√µes

Sugest√µes e melhorias s√£o bem-vindas! Sinta-se livre para:
- Reportar bugs
- Sugerir novas funcionalidades
- Melhorar a documenta√ß√£o
- Propor otimiza√ß√µes

---

**Desenvolvido com ‚ù§Ô∏è para estudos e portfolio**
